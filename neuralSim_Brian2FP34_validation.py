# -*- coding: utf-8 -*-
"""
Created on Wed Dec 13 13:50:22 2023

@author: Daeyoung Kim
"""

import sys, os
import h5py
import pickle
import neuralSim.parameters as param
import numpy as np
import neuralSim.compiler as compiler
import neuralSim.synapticTable as synTable
import neuralSim.inputSpikesGen as inSpike
import neuralSim.eventAnalysis as eventAnalysis
import matplotlib.pyplot as plt
import neuralSim.poissonSpike as spikes
import neuralSim.MNISTdataset as MNIST
import time as t
from datetime import date
import datetime
import brian2 as b2
import random

np.set_printoptions(threshold=sys.maxsize, linewidth=np.inf)

inputSpikeFilename = "testByte.nam"
synTableFilePrefix = "SynTableWrite"
fname = "testExpConf.exp"
nfname = "testNeuronConf.nac"
conffname = "neuplusconf.txt"
synfname = "testRead.dat"

b2.defaultclock.dt = 0.5*b2.ms

parameters = {}
parameters['apre'] = 16.
parameters['gamma'] = -2.
parameters['neuron_tau'] = 20.
parameters['synapse_tau'] = 20.
parameters['refractory'] = 0.
parameters['threshold'] = 100.
parameters['wmax'] = 248.
parameters['winit'] = 32.


# %% Experiment Configuration

testSet = compiler.expSetupCompiler(fname, nfname)
testSet.setExperimentConf("EVENT_SAVE_MODE", True)
testSet.setExperimentConf("EXP_TIME", 100)
testSet.setExperimentConf("TIME_ACCEL_MODE", True)
testSet.setExperimentConf("INTERNAL_ROUTING_MODE", True)
testSet.setExperimentConf("INPUT_SPIKES_FILE", inputSpikeFilename)
testSet.setExperimentConf("SYN_TABLE_FILE_PREFIX", synTableFilePrefix)
testSet.setExperimentConf("SYN_TABLE_READ_FILE", synfname)
testSet.setExperimentConf("SYN_TABLE_READ_START", 0)
testSet.setExperimentConf("SYN_TABLE_READ_COUNT", 1024)

# %% FPGA Configuration

testSet.setFPGAConfiguration("CHIP_CLOCK", 150)
testSet.setFPGAConfiguration("ROUTER_SYN_OUTPUT_DISABLE", 0)
# testSet.setFPGAConfiguration("ARRAY_OUTPUT_OFF",  0)

# %% Learning Engine Configuration

testSet.setLearningEngine("LC_TIMECONSTANT", 0, parameters['synapse_tau'])
testSet.setLearningEngine("MAX_SYN_WEIGHT", 0, parameters['wmax'])
testSet.setLearningEngine("TRACE_UPDATE_AMOUNT", 0, 0, parameters['apre'])
testSet.setLearningEngine("POST_TRACE_SCALE", 0, 0, parameters['gamma'])
testSet.setLearningEngine("LEARNING_RULE", 0, 1, 0, 0, 0, 0)

# %% input spike pattern generation

input_spike_idx = np.array([1, 0])
input_spike_time = np.array([0.030, 0.032]) #second

events = [input_spike_time, input_spike_idx]

inputSpike = inSpike.MakeNeuPLUSByteFile(deltat=1000)


inputSpike.events_to_bytefile(events=events, 
                              byte_file_name=inputSpikeFilename, 
                              conf_events=[[0.030], # time
                                           [0],     # core
                                           [0],    # addr
                                           [4]],   # value
                              # conf_events = [],
                              weight_single=parameters['threshold']+10)

testSet.setNeuronCoreConf([0],                                  # Core Number
                          [parameters['neuron_tau']],           # Membrane time constant
                          [parameters['refractory']],           # Refractory period
                          [parameters['threshold']],            # Threshold
                          [0],                                  # Synaptic Gain
                          [0])                                  # Stochasticity

testSet.setNeuronCoreConf([1],                                  # Core Number
                          [parameters['neuron_tau']],           # Membrane time constant
                          [parameters['refractory']],           # Refractory period
                          [parameters['threshold']],            # Threshold
                          [0],                                  # Synaptic Gain
                          [0])                                  # Stochasticity

testSet.genExpConfFile(conffname)

SynTable = synTable.synapticTable(1, 1024, 1024)

SynTable.createConnections(source = [0], 
                            destination = [1], 
                            mode = 'one', 
                            probability = 1, 
                            weight = parameters['winit'], 
                            wmax = parameters['wmax'], 
                            delay = 0, 
                            dmax = 0, 
                            synType = 'exc', 
                            trainable = True)

SynMapCompiled = compiler.synMapCompiler(synTableFilePrefix)
SynMapCompiled.generateSynMap(synTable=SynTable, inputNeurons=[range(2*1024)])

# %% Run on NeuPLUS system
elapsed_time = param.NeuPLUSRun('-GUIModeOff', '-conf', conffname)
print("Result time : ", elapsed_time)

# %% Event analysis

event_results = eventAnalysis.eventAnalysis(param.NeuPLUSResultFolder + '2024' + date.today().strftime("%m%d") + "/")

output_spike_idx = event_results.spikes[1]
output_spike_time  = event_results.spikes[0]

# %% Synapse table read

synMapDecompile     = compiler.synMapDecompiler(synfname)
synTable_read       = synTable.synapticTable()
synDecompiledList   = synMapDecompile.decompileSynMap()
synTable_read       = synTable_read.createFromSynapseList(synDecompiledList)

# %% Brian2 FP34 emulation

def checkAccurateTimeConst(timeConstant, refractory, timeAccelTimestep, timeAccelResolution):
    unitTimestep = timeAccelTimestep # ms
    updateCycle = 2**timeAccelResolution # count from MSB of mantissa, max 10 
    
    ChipPrescaler = (timeConstant * 0.693147 / updateCycle / unitTimestep) - 1
    if ChipPrescaler <= 0:
        ChipPrescaler = 0.1
    
    ActualTimeconst = (int(ChipPrescaler) + 1) * unitTimestep * updateCycle / 0.693147
    ActualArrayTimer = unitTimestep * (int(ChipPrescaler) + 1) / (1024/updateCycle)
    ActualRefractory = (int((refractory / ActualArrayTimer)) >> (10 - timeAccelResolution)) * 2**(10-timeAccelResolution) * ActualArrayTimer
    
    propUnitstep = timeConstant * 0.693147 / updateCycle
    
    return ActualTimeconst, ActualRefractory

# def get_nearest_value34(before_value):
#     sign = before_value >= 0 
    
#     if sign:
#         pass
#     else:
#         before_value = np.abs(before_value)
    
#     reference = np.array([  0.      ,   1.0625   ,   1.125   ,   1.1875   ,   1.25    ,   1.3125   ,
#                             1.375   ,   1.4375   ,   1.5     ,   1.5625   ,   1.625   ,   1.6875   ,
#                             1.75    ,   1.8125   ,   1.875   ,   1.9375   ,   2.      ,   2.125    ,
#                             2.25    ,   2.375    ,   2.5     ,   2.625    ,   2.75    ,   2.875    ,
#                             3.      ,   3.125    ,   3.25    ,   3.375    ,   3.5     ,   3.625    ,
#                             3.75    ,   3.875    ,   4.      ,   4.25     ,   4.5     ,   4.75     ,
#                             5.      ,   5.25     ,   5.5     ,   5.75     ,   6.      ,   6.25     ,
#                             6.5     ,   6.75     ,   7.      ,   7.25     ,   7.5     ,   7.75     ,
#                             8.      ,   8.5      ,   9.      ,   9.5      ,   10.     ,   10.5     ,
#                             11.     ,   11.5     ,   12.     ,   12.5     ,   13.     ,   13.5     ,
#                             14.     ,   14.5     ,   15.     ,   15.5     ,   16.     ,   17.      ,
#                             18.     ,   19.      ,   20.     ,   21.      ,   22.     ,   23.      ,
#                             24.     ,   25.      ,   26.     ,   27.      ,   28.     ,   29.      ,
#                             30.     ,   31.      ,   32.     ,   34.      ,   36.     ,   38.      ,
#                             40.     ,   42.      ,   44.     ,   46.      ,   48.     ,   50.      ,
#                             52.     ,   54.      ,   56.     ,   58.      ,   60.     ,   62.      ,
#                             64.     ,   68.      ,   72.     ,   76.      ,   80.     ,   84.      ,
#                             88.     ,   92.      ,   96.     ,   100.     ,   104.    ,   108.     ,
#                             112.    ,   116.     ,   120.    ,   124.     ,   128.    ,   136.     ,
#                             144.    ,   152.     ,   160.    ,   168.     ,   176.    ,   184.     ,
#                             192.    ,   200.     ,   208.    ,   216.     ,   224.    ,   232.     ,
#                             240.    ,   248.                                                          ])
    
#     if type(before_value) is not np.ndarray:
#         after_value = reference[np.where((before_value - reference) >= 0)[0][-1]]
    
#     else:
#         after_value = np.zeros_like(before_value)
#         for i in range(len(before_value)):
#             after_value[i] = reference[np.where((before_value[i] - reference) >= 0)[0][-1]]
    
#     if sign:
#         return after_value
#     else:
#         return -1 * after_value

    
    
# def get_nearest_value64(before_value):
#     sign = before_value >= 0 
    
#     if sign:
#         pass
#     else:
#         before_value = np.abs(before_value)
    
#     reference = np.array([    0.     ,     1.01562,     1.03125,     1.04688,     1.0625 ,     1.07812,     1.09375,     1.10938,     
#                           1.125  ,     1.14062,     1.15625,     1.17188,     1.1875 ,     1.20312,     1.21875,     1.23438,     
#                           1.25   ,     1.26562,     1.28125,     1.29688,     1.3125 ,     1.32812,     1.34375,     1.35938,     
#                           1.375  ,     1.39062,     1.40625,     1.42188,     1.4375 ,     1.45312,     1.46875,     1.48438,     
#                           1.5    ,     1.51562,     1.53125,     1.54688,     1.5625 ,     1.57812,     1.59375,     1.60938,     
#                           1.625  ,     1.64062,     1.65625,     1.67188,     1.6875 ,     1.70312,     1.71875,     1.73438,     
#                           1.75   ,     1.76562,     1.78125,     1.79688,     1.8125 ,     1.82812,     1.84375,     1.85938,     
#                           1.875  ,     1.89062,     1.90625,     1.92188,     1.9375 ,     1.95312,     1.96875,     1.98438,     
#                           2.     ,     2.03125,     2.0625 ,     2.09375,     2.125  ,     2.15625,     2.1875 ,     2.21875,     
#                           2.25   ,     2.28125,     2.3125 ,     2.34375,     2.375  ,     2.40625,     2.4375 ,     2.46875,     
#                           2.5    ,     2.53125,     2.5625 ,     2.59375,     2.625  ,     2.65625,     2.6875 ,     2.71875,     
#                           2.75   ,     2.78125,     2.8125 ,     2.84375,     2.875  ,     2.90625,     2.9375 ,     2.96875,     
#                           3.     ,     3.03125,     3.0625 ,     3.09375,     3.125  ,     3.15625,     3.1875 ,     3.21875,     
#                           3.25   ,     3.28125,     3.3125 ,     3.34375,     3.375  ,     3.40625,     3.4375 ,     3.46875,     
#                           3.5    ,     3.53125,     3.5625 ,     3.59375,     3.625  ,     3.65625,     3.6875 ,     3.71875,     
#                           3.75   ,     3.78125,     3.8125 ,     3.84375,     3.875  ,     3.90625,     3.9375 ,     3.96875,     
#                           4.     ,     4.0625 ,     4.125  ,     4.1875 ,     4.25   ,     4.3125 ,     4.375  ,     4.4375 ,     
#                           4.5    ,     4.5625 ,     4.625  ,     4.6875 ,     4.75   ,     4.8125 ,     4.875  ,     4.9375 ,     
#                           5.     ,     5.0625 ,     5.125  ,     5.1875 ,     5.25   ,     5.3125 ,     5.375  ,     5.4375 ,     
#                           5.5    ,     5.5625 ,     5.625  ,     5.6875 ,     5.75   ,     5.8125 ,     5.875  ,     5.9375 ,     
#                           6.     ,     6.0625 ,     6.125  ,     6.1875 ,     6.25   ,     6.3125 ,     6.375  ,     6.4375 ,     
#                           6.5    ,     6.5625 ,     6.625  ,     6.6875 ,     6.75   ,     6.8125 ,     6.875  ,     6.9375 ,     
#                           7.     ,     7.0625 ,     7.125  ,     7.1875 ,     7.25   ,     7.3125 ,     7.375  ,     7.4375 ,     
#                           7.5    ,     7.5625 ,     7.625  ,     7.6875 ,     7.75   ,     7.8125 ,     7.875  ,     7.9375 ,     
#                           8.     ,     8.125  ,     8.25   ,     8.375  ,     8.5    ,     8.625  ,     8.75   ,     8.875  ,     
#                           9.     ,     9.125  ,     9.25   ,     9.375  ,     9.5    ,     9.625  ,     9.75   ,     9.875  ,    
#                           10.     ,    10.125  ,    10.25   ,    10.375  ,    10.5    ,    10.625  ,    10.75   ,    10.875  ,    
#                           11.     ,    11.125  ,    11.25   ,    11.375  ,    11.5    ,    11.625  ,    11.75   ,    11.875  ,    
#                           12.     ,    12.125  ,    12.25   ,    12.375  ,    12.5    ,    12.625  ,    12.75   ,    12.875  ,    
#                           13.     ,    13.125  ,    13.25   ,    13.375  ,    13.5    ,    13.625  ,    13.75   ,    13.875  ,    
#                           14.     ,    14.125  ,    14.25   ,    14.375  ,    14.5    ,    14.625  ,    14.75   ,    14.875  ,    
#                           15.     ,    15.125  ,    15.25   ,    15.375  ,    15.5    ,    15.625  ,    15.75   ,    15.875  ,    
#                           16.     ,    16.25   ,    16.5    ,    16.75   ,    17.     ,    17.25   ,    17.5    ,    17.75   ,    
#                           18.     ,    18.25   ,    18.5    ,    18.75   ,    19.     ,    19.25   ,    19.5    ,    19.75   ,    
#                           20.     ,    20.25   ,    20.5    ,    20.75   ,    21.     ,    21.25   ,    21.5    ,    21.75   ,    
#                           22.     ,    22.25   ,    22.5    ,    22.75   ,    23.     ,    23.25   ,    23.5    ,    23.75   ,    
#                           24.     ,    24.25   ,    24.5    ,    24.75   ,    25.     ,    25.25   ,    25.5    ,    25.75   ,    
#                           26.     ,    26.25   ,    26.5    ,    26.75   ,    27.     ,    27.25   ,    27.5    ,    27.75   ,    
#                           28.     ,    28.25   ,    28.5    ,    28.75   ,    29.     ,    29.25   ,    29.5    ,    29.75   ,    
#                           30.     ,    30.25   ,    30.5    ,    30.75   ,    31.     ,    31.25   ,    31.5    ,    31.75   ,    
#                           32.     ,    32.5    ,    33.     ,    33.5    ,    34.     ,    34.5    ,    35.     ,    35.5    ,    
#                           36.     ,    36.5    ,    37.     ,    37.5    ,    38.     ,    38.5    ,    39.     ,    39.5    ,    
#                           40.     ,    40.5    ,    41.     ,    41.5    ,    42.     ,    42.5    ,    43.     ,    43.5    ,    
#                           44.     ,    44.5    ,    45.     ,    45.5    ,    46.     ,    46.5    ,    47.     ,    47.5    ,    
#                           48.     ,    48.5    ,    49.     ,    49.5    ,    50.     ,    50.5    ,    51.     ,    51.5    ,    
#                           52.     ,    52.5    ,    53.     ,    53.5    ,    54.     ,    54.5    ,    55.     ,    55.5    ,    
#                           56.     ,    56.5    ,    57.     ,    57.5    ,    58.     ,    58.5    ,    59.     ,    59.5    ,    
#                           60.     ,    60.5    ,    61.     ,    61.5    ,    62.     ,    62.5    ,    63.     ,    63.5    ,    
#                           64.     ,    65.     ,    66.     ,    67.     ,    68.     ,    69.     ,    70.     ,    71.     ,    
#                           72.     ,    73.     ,    74.     ,    75.     ,    76.     ,    77.     ,    78.     ,    79.     ,    
#                           80.     ,    81.     ,    82.     ,    83.     ,    84.     ,    85.     ,    86.     ,    87.     ,    
#                           88.     ,    89.     ,    90.     ,    91.     ,    92.     ,    93.     ,    94.     ,    95.     ,    
#                           96.     ,    97.     ,    98.     ,    99.     ,   100.     ,   101.     ,   102.     ,   103.     ,   
#                           104.     ,   105.     ,   106.     ,   107.     ,   108.     ,   109.     ,   110.     ,   111.     ,   
#                           112.     ,   113.     ,   114.     ,   115.     ,   116.     ,   117.     ,   118.     ,   119.     ,  
#                           120.     ,   121.     ,   122.     ,   123.     ,   124.     ,   125.     ,   126.     ,   127.     ,   
#                           128.     ,   130.     ,   132.     ,   134.     ,   136.     ,   138.     ,   140.     ,   142.     ,   
#                           144.     ,   146.     ,   148.     ,   150.     ,   152.     ,   154.     ,   156.     ,   158.     ,   
#                           160.     ,   162.     ,   164.     ,   166.     ,   168.     ,   170.     ,   172.     ,   174.     ,   
#                           176.     ,   178.     ,   180.     ,   182.     ,   184.     ,   186.     ,   188.     ,   190.     ,   
#                           192.     ,   194.     ,   196.     ,   198.     ,   200.     ,   202.     ,   204.     ,   206.     ,   
#                           208.     ,   210.     ,   212.     ,   214.     ,   216.     ,   218.     ,   220.     ,   222.     ,   
#                           224.     ,   226.     ,   228.     ,   230.     ,   232.     ,   234.     ,   236.     ,   238.     ,   
#                           240.     ,   242.     ,   244.     ,   246.     ,   248.     ,   250.     ,   252.     ,   254.     ,   
#                           256.     ,   260.     ,   264.     ,   268.     ,   272.     ,   276.     ,   280.     ,   284.     ,   
#                           288.     ,   292.     ,   296.     ,   300.     ,   304.     ,   308.     ,   312.     ,   316.     ,   
#                           320.     ,   324.     ,   328.     ,   332.     ,   336.     ,   340.     ,   344.     ,   348.     ,   
#                           352.     ,   356.     ,   360.     ,   364.     ,   368.     ,   372.     ,   376.     ,   380.     ,   
#                           384.     ,   388.     ,   392.     ,   396.     ,   400.     ,   404.     ,   408.     ,   412.     ,   
#                           416.     ,   420.     ,   424.     ,   428.     ,   432.     ,   436.     ,   440.     ,   444.     ,   
#                           448.     ,   452.     ,   456.     ,   460.     ,   464.     ,   468.     ,   472.     ,   476.     ,   
#                           480.     ,   484.     ,   488.     ,   492.     ,   496.     ,   500.     ,   504.     ,   508.     ,   
#                           512.     ,   520.     ,   528.     ,   536.     ,   544.     ,   552.     ,   560.     ,   568.     ,   
#                           576.     ,   584.     ,   592.     ,   600.     ,   608.     ,   616.     ,   624.     ,   632.     ,   
#                           640.     ,   648.     ,   656.     ,   664.     ,   672.     ,   680.     ,   688.     ,   696.     ,   
#                           704.     ,   712.     ,   720.     ,   728.     ,   736.     ,   744.     ,   752.     ,   760.     ,   
#                           768.     ,   776.     ,   784.     ,   792.     ,   800.     ,   808.     ,   816.     ,   824.     ,   
#                           832.     ,   840.     ,   848.     ,   856.     ,   864.     ,   872.     ,   880.     ,   888.     ,   
#                           896.     ,   904.     ,   912.     ,   920.     ,   928.     ,   936.     ,   944.     ,   952.     ,   
#                           960.     ,   968.     ,   976.     ,   984.     ,   992.     ,  1000.     ,  1008.     ,  1016.     ,  
#                           1024.     ,  1040.     ,  1056.     ,  1072.     ,  1088.     ,  1104.     ,  1120.     ,  1136.     , 
#                           1152.     ,  1168.     ,  1184.     ,  1200.     ,  1216.     ,  1232.     ,  1248.     ,  1264.     ,  
#                           1280.     ,  1296.     ,  1312.     ,  1328.     ,  1344.     ,  1360.     ,  1376.     ,  1392.     ,  
#                           1408.     ,  1424.     ,  1440.     ,  1456.     ,  1472.     ,  1488.     ,  1504.     ,  1520.     ,  
#                           1536.     ,  1552.     ,  1568.     ,  1584.     ,  1600.     ,  1616.     ,  1632.     ,  1648.     ,  
#                           1664.     ,  1680.     ,  1696.     ,  1712.     ,  1728.     ,  1744.     ,  1760.     ,  1776.     ,  
#                           1792.     ,  1808.     ,  1824.     ,  1840.     ,  1856.     ,  1872.     ,  1888.     ,  1904.     ,  
#                           1920.     ,  1936.     ,  1952.     ,  1968.     ,  1984.     ,  2000.     ,  2016.     ,  2032.     ,  
#                           2048.     ,  2080.     ,  2112.     ,  2144.     ,  2176.     ,  2208.     ,  2240.     ,  2272.     ,  
#                           2304.     ,  2336.     ,  2368.     ,  2400.     ,  2432.     ,  2464.     ,  2496.     ,  2528.     ,  
#                           2560.     ,  2592.     ,  2624.     ,  2656.     ,  2688.     ,  2720.     ,  2752.     ,  2784.     ,  
#                           2816.     ,  2848.     ,  2880.     ,  2912.     ,  2944.     ,  2976.     ,  3008.     ,  3040.     ,  
#                           3072.     ,  3104.     ,  3136.     ,  3168.     ,  3200.     ,  3232.     ,  3264.     ,  3296.     ,  
#                           3328.     ,  3360.     ,  3392.     ,  3424.     ,  3456.     ,  3488.     ,  3520.     ,  3552.     ,  
#                           3584.     ,  3616.     ,  3648.     ,  3680.     ,  3712.     ,  3744.     ,  3776.     ,  3808.     ,  
#                           3840.     ,  3872.     ,  3904.     ,  3936.     ,  3968.     ,  4000.     ,  4032.     ,  4064.     ,  
#                           4096.     ,  4160.     ,  4224.     ,  4288.     ,  4352.     ,  4416.     ,  4480.     ,  4544.     ,  
#                           4608.     ,  4672.     ,  4736.     ,  4800.     ,  4864.     ,  4928.     ,  4992.     ,  5056.     ,  
#                           5120.     ,  5184.     ,  5248.     ,  5312.     ,  5376.     ,  5440.     ,  5504.     ,  5568.     ,  
#                           5632.     ,  5696.     ,  5760.     ,  5824.     ,  5888.     ,  5952.     ,  6016.     ,  6080.     ,  
#                           6144.     ,  6208.     ,  6272.     ,  6336.     ,  6400.     ,  6464.     ,  6528.     ,  6592.     ,  
#                           6656.     ,  6720.     ,  6784.     ,  6848.     ,  6912.     ,  6976.     ,  7040.     ,  7104.     ,  
#                           7168.     ,  7232.     ,  7296.     ,  7360.     ,  7424.     ,  7488.     ,  7552.     ,  7616.     ,  
#                           7680.     ,  7744.     ,  7808.     ,  7872.     ,  7936.     ,  8000.     ,  8064.     ,  8128.     ,  
#                           8192.     ,  8320.     ,  8448.     ,  8576.     ,  8704.     ,  8832.     ,  8960.     ,  9088.     ,  
#                           9216.     ,  9344.     ,  9472.     ,  9600.     ,  9728.     ,  9856.     ,  9984.     , 10112.     , 
#                           10240.     , 10368.     , 10496.     , 10624.     , 10752.     , 10880.     , 11008.     , 11136.     , 
#                           11264.     , 11392.     , 11520.     , 11648.     , 11776.     , 11904.     , 12032.     , 12160.     , 
#                           12288.     , 12416.     , 12544.     , 12672.     , 12800.     , 12928.     , 13056.     , 13184.     , 
#                           13312.     , 13440.     , 13568.     , 13696.     , 13824.     , 13952.     , 14080.     , 14208.     , 
#                           14336.     , 14464.     , 14592.     , 14720.     , 14848.     , 14976.     , 15104.     , 15232.     , 
#                           15360.     , 15488.     , 15616.     , 15744.     , 15872.     , 16000.     , 16128.     , 16256.     , 
#                           16384.     , 16640.     , 16896.     , 17152.     , 17408.     , 17664.     , 17920.     , 18176.     , 
#                           18432.     , 18688.     , 18944.     , 19200.     , 19456.     , 19712.     , 19968.     , 20224.     , 
#                           20480.     , 20736.     , 20992.     , 21248.     , 21504.     , 21760.     , 22016.     , 22272.     , 
#                           22528.     , 22784.     , 23040.     , 23296.     , 23552.     , 23808.     , 24064.     , 24320.     , 
#                           24576.     , 24832.     , 25088.     , 25344.     , 25600.     , 25856.     , 26112.     , 26368.     , 
#                           26624.     , 26880.     , 27136.     , 27392.     , 27648.     , 27904.     , 28160.     , 28416.     , 
#                           28672.     , 28928.     , 29184.     , 29440.     , 29696.     , 29952.     , 30208.     , 30464.     , 
#                           30720.     , 30976.     , 31232.     , 31488.     , 31744.     , 32000.     , 32256.     , 32512.     , 
#                           32768.     , 33280.     , 33792.     , 34304.     , 34816.     , 35328.     , 35840.     , 36352.     , 
#                           36864.     , 37376.     , 37888.     , 38400.     , 38912.     , 39424.     , 39936.     , 40448.     , 
#                           40960.     , 41472.     , 41984.     , 42496.     , 43008.     , 43520.     , 44032.     , 44544.     , 
#                           45056.     , 45568.     , 46080.     , 46592.     , 47104.     , 47616.     , 48128.     , 48640.     , 
#                           49152.     , 49664.     , 50176.     , 50688.     , 51200.     , 51712.     , 52224.     , 52736.     , 
#                           53248.     , 53760.     , 54272.     , 54784.     , 55296.     , 55808.     , 56320.     , 56832.     , 
#                           57344.     , 57856.     , 58368.     , 58880.     , 59392.     , 59904.     , 60416.     , 60928.     , 
#                           61440.     , 61952.     , 62464.     , 62976.     , 63488.     , 64000.     , 64512.     , 65024.     ])
    
#     if type(before_value) is not np.ndarray:
#         after_value = reference[np.where((before_value - reference) >= 0)[0][-1]]
    
#     else:
#         after_value = np.zeros_like(before_value)
#         for i in range(len(before_value)):
#             after_value[i] = reference[np.where((before_value[i] - reference) >= 0)[0][-1]]
    
#     if sign:
#         return after_value
#     else:
#         return -1 * after_value
    
def get_nearest_value34(before_value):
    
    reference = np.array([  0.      ,   1.0625   ,   1.125   ,   1.1875   ,   1.25    ,   1.3125   ,
                            1.375   ,   1.4375   ,   1.5     ,   1.5625   ,   1.625   ,   1.6875   ,
                            1.75    ,   1.8125   ,   1.875   ,   1.9375   ,   2.      ,   2.125    ,
                            2.25    ,   2.375    ,   2.5     ,   2.625    ,   2.75    ,   2.875    ,
                            3.      ,   3.125    ,   3.25    ,   3.375    ,   3.5     ,   3.625    ,
                            3.75    ,   3.875    ,   4.      ,   4.25     ,   4.5     ,   4.75     ,
                            5.      ,   5.25     ,   5.5     ,   5.75     ,   6.      ,   6.25     ,
                            6.5     ,   6.75     ,   7.      ,   7.25     ,   7.5     ,   7.75     ,
                            8.      ,   8.5      ,   9.      ,   9.5      ,   10.     ,   10.5     ,
                            11.     ,   11.5     ,   12.     ,   12.5     ,   13.     ,   13.5     ,
                            14.     ,   14.5     ,   15.     ,   15.5     ,   16.     ,   17.      ,
                            18.     ,   19.      ,   20.     ,   21.      ,   22.     ,   23.      ,
                            24.     ,   25.      ,   26.     ,   27.      ,   28.     ,   29.      ,
                            30.     ,   31.      ,   32.     ,   34.      ,   36.     ,   38.      ,
                            40.     ,   42.      ,   44.     ,   46.      ,   48.     ,   50.      ,
                            52.     ,   54.      ,   56.     ,   58.      ,   60.     ,   62.      ,
                            64.     ,   68.      ,   72.     ,   76.      ,   80.     ,   84.      ,
                            88.     ,   92.      ,   96.     ,   100.     ,   104.    ,   108.     ,
                            112.    ,   116.     ,   120.    ,   124.     ,   128.    ,   136.     ,
                            144.    ,   152.     ,   160.    ,   168.     ,   176.    ,   184.     ,
                            192.    ,   200.     ,   208.    ,   216.     ,   224.    ,   232.     ,
                            240.    ,   248.                                                          ])
    
    before_value_array = np.atleast_1d(before_value)
    sign_array = np.sign(before_value_array)
    abs_before_value = np.abs(before_value_array)
    abs_diff = np.abs(abs_before_value[:, None] - reference)
    abs_diff[abs_before_value[:, None] < reference] = np.inf
    indices = np.argmin(abs_diff, axis=1)

    after_value = reference[indices]
    result = sign_array * after_value
    
    return result if isinstance(before_value, np.ndarray) else result[0]


def get_nearest_value64(before_value):
    
    
    reference = np.array([    0.     ,     1.01562,     1.03125,     1.04688,     1.0625 ,     1.07812,     1.09375,     1.10938,     
                          1.125  ,     1.14062,     1.15625,     1.17188,     1.1875 ,     1.20312,     1.21875,     1.23438,     
                          1.25   ,     1.26562,     1.28125,     1.29688,     1.3125 ,     1.32812,     1.34375,     1.35938,     
                          1.375  ,     1.39062,     1.40625,     1.42188,     1.4375 ,     1.45312,     1.46875,     1.48438,     
                          1.5    ,     1.51562,     1.53125,     1.54688,     1.5625 ,     1.57812,     1.59375,     1.60938,     
                          1.625  ,     1.64062,     1.65625,     1.67188,     1.6875 ,     1.70312,     1.71875,     1.73438,     
                          1.75   ,     1.76562,     1.78125,     1.79688,     1.8125 ,     1.82812,     1.84375,     1.85938,     
                          1.875  ,     1.89062,     1.90625,     1.92188,     1.9375 ,     1.95312,     1.96875,     1.98438,     
                          2.     ,     2.03125,     2.0625 ,     2.09375,     2.125  ,     2.15625,     2.1875 ,     2.21875,     
                          2.25   ,     2.28125,     2.3125 ,     2.34375,     2.375  ,     2.40625,     2.4375 ,     2.46875,     
                          2.5    ,     2.53125,     2.5625 ,     2.59375,     2.625  ,     2.65625,     2.6875 ,     2.71875,     
                          2.75   ,     2.78125,     2.8125 ,     2.84375,     2.875  ,     2.90625,     2.9375 ,     2.96875,     
                          3.     ,     3.03125,     3.0625 ,     3.09375,     3.125  ,     3.15625,     3.1875 ,     3.21875,     
                          3.25   ,     3.28125,     3.3125 ,     3.34375,     3.375  ,     3.40625,     3.4375 ,     3.46875,     
                          3.5    ,     3.53125,     3.5625 ,     3.59375,     3.625  ,     3.65625,     3.6875 ,     3.71875,     
                          3.75   ,     3.78125,     3.8125 ,     3.84375,     3.875  ,     3.90625,     3.9375 ,     3.96875,     
                          4.     ,     4.0625 ,     4.125  ,     4.1875 ,     4.25   ,     4.3125 ,     4.375  ,     4.4375 ,     
                          4.5    ,     4.5625 ,     4.625  ,     4.6875 ,     4.75   ,     4.8125 ,     4.875  ,     4.9375 ,     
                          5.     ,     5.0625 ,     5.125  ,     5.1875 ,     5.25   ,     5.3125 ,     5.375  ,     5.4375 ,     
                          5.5    ,     5.5625 ,     5.625  ,     5.6875 ,     5.75   ,     5.8125 ,     5.875  ,     5.9375 ,     
                          6.     ,     6.0625 ,     6.125  ,     6.1875 ,     6.25   ,     6.3125 ,     6.375  ,     6.4375 ,     
                          6.5    ,     6.5625 ,     6.625  ,     6.6875 ,     6.75   ,     6.8125 ,     6.875  ,     6.9375 ,     
                          7.     ,     7.0625 ,     7.125  ,     7.1875 ,     7.25   ,     7.3125 ,     7.375  ,     7.4375 ,     
                          7.5    ,     7.5625 ,     7.625  ,     7.6875 ,     7.75   ,     7.8125 ,     7.875  ,     7.9375 ,     
                          8.     ,     8.125  ,     8.25   ,     8.375  ,     8.5    ,     8.625  ,     8.75   ,     8.875  ,     
                          9.     ,     9.125  ,     9.25   ,     9.375  ,     9.5    ,     9.625  ,     9.75   ,     9.875  ,    
                          10.     ,    10.125  ,    10.25   ,    10.375  ,    10.5    ,    10.625  ,    10.75   ,    10.875  ,    
                          11.     ,    11.125  ,    11.25   ,    11.375  ,    11.5    ,    11.625  ,    11.75   ,    11.875  ,    
                          12.     ,    12.125  ,    12.25   ,    12.375  ,    12.5    ,    12.625  ,    12.75   ,    12.875  ,    
                          13.     ,    13.125  ,    13.25   ,    13.375  ,    13.5    ,    13.625  ,    13.75   ,    13.875  ,    
                          14.     ,    14.125  ,    14.25   ,    14.375  ,    14.5    ,    14.625  ,    14.75   ,    14.875  ,    
                          15.     ,    15.125  ,    15.25   ,    15.375  ,    15.5    ,    15.625  ,    15.75   ,    15.875  ,    
                          16.     ,    16.25   ,    16.5    ,    16.75   ,    17.     ,    17.25   ,    17.5    ,    17.75   ,    
                          18.     ,    18.25   ,    18.5    ,    18.75   ,    19.     ,    19.25   ,    19.5    ,    19.75   ,    
                          20.     ,    20.25   ,    20.5    ,    20.75   ,    21.     ,    21.25   ,    21.5    ,    21.75   ,    
                          22.     ,    22.25   ,    22.5    ,    22.75   ,    23.     ,    23.25   ,    23.5    ,    23.75   ,    
                          24.     ,    24.25   ,    24.5    ,    24.75   ,    25.     ,    25.25   ,    25.5    ,    25.75   ,    
                          26.     ,    26.25   ,    26.5    ,    26.75   ,    27.     ,    27.25   ,    27.5    ,    27.75   ,    
                          28.     ,    28.25   ,    28.5    ,    28.75   ,    29.     ,    29.25   ,    29.5    ,    29.75   ,    
                          30.     ,    30.25   ,    30.5    ,    30.75   ,    31.     ,    31.25   ,    31.5    ,    31.75   ,    
                          32.     ,    32.5    ,    33.     ,    33.5    ,    34.     ,    34.5    ,    35.     ,    35.5    ,    
                          36.     ,    36.5    ,    37.     ,    37.5    ,    38.     ,    38.5    ,    39.     ,    39.5    ,    
                          40.     ,    40.5    ,    41.     ,    41.5    ,    42.     ,    42.5    ,    43.     ,    43.5    ,    
                          44.     ,    44.5    ,    45.     ,    45.5    ,    46.     ,    46.5    ,    47.     ,    47.5    ,    
                          48.     ,    48.5    ,    49.     ,    49.5    ,    50.     ,    50.5    ,    51.     ,    51.5    ,    
                          52.     ,    52.5    ,    53.     ,    53.5    ,    54.     ,    54.5    ,    55.     ,    55.5    ,    
                          56.     ,    56.5    ,    57.     ,    57.5    ,    58.     ,    58.5    ,    59.     ,    59.5    ,    
                          60.     ,    60.5    ,    61.     ,    61.5    ,    62.     ,    62.5    ,    63.     ,    63.5    ,    
                          64.     ,    65.     ,    66.     ,    67.     ,    68.     ,    69.     ,    70.     ,    71.     ,    
                          72.     ,    73.     ,    74.     ,    75.     ,    76.     ,    77.     ,    78.     ,    79.     ,    
                          80.     ,    81.     ,    82.     ,    83.     ,    84.     ,    85.     ,    86.     ,    87.     ,    
                          88.     ,    89.     ,    90.     ,    91.     ,    92.     ,    93.     ,    94.     ,    95.     ,    
                          96.     ,    97.     ,    98.     ,    99.     ,   100.     ,   101.     ,   102.     ,   103.     ,   
                          104.     ,   105.     ,   106.     ,   107.     ,   108.     ,   109.     ,   110.     ,   111.     ,   
                          112.     ,   113.     ,   114.     ,   115.     ,   116.     ,   117.     ,   118.     ,   119.     ,  
                          120.     ,   121.     ,   122.     ,   123.     ,   124.     ,   125.     ,   126.     ,   127.     ,   
                          128.     ,   130.     ,   132.     ,   134.     ,   136.     ,   138.     ,   140.     ,   142.     ,   
                          144.     ,   146.     ,   148.     ,   150.     ,   152.     ,   154.     ,   156.     ,   158.     ,   
                          160.     ,   162.     ,   164.     ,   166.     ,   168.     ,   170.     ,   172.     ,   174.     ,   
                          176.     ,   178.     ,   180.     ,   182.     ,   184.     ,   186.     ,   188.     ,   190.     ,   
                          192.     ,   194.     ,   196.     ,   198.     ,   200.     ,   202.     ,   204.     ,   206.     ,   
                          208.     ,   210.     ,   212.     ,   214.     ,   216.     ,   218.     ,   220.     ,   222.     ,   
                          224.     ,   226.     ,   228.     ,   230.     ,   232.     ,   234.     ,   236.     ,   238.     ,   
                          240.     ,   242.     ,   244.     ,   246.     ,   248.     ,   250.     ,   252.     ,   254.     ,   
                          256.     ,   260.     ,   264.     ,   268.     ,   272.     ,   276.     ,   280.     ,   284.     ,   
                          288.     ,   292.     ,   296.     ,   300.     ,   304.     ,   308.     ,   312.     ,   316.     ,   
                          320.     ,   324.     ,   328.     ,   332.     ,   336.     ,   340.     ,   344.     ,   348.     ,   
                          352.     ,   356.     ,   360.     ,   364.     ,   368.     ,   372.     ,   376.     ,   380.     ,   
                          384.     ,   388.     ,   392.     ,   396.     ,   400.     ,   404.     ,   408.     ,   412.     ,   
                          416.     ,   420.     ,   424.     ,   428.     ,   432.     ,   436.     ,   440.     ,   444.     ,   
                          448.     ,   452.     ,   456.     ,   460.     ,   464.     ,   468.     ,   472.     ,   476.     ,   
                          480.     ,   484.     ,   488.     ,   492.     ,   496.     ,   500.     ,   504.     ,   508.     ,   
                          512.     ,   520.     ,   528.     ,   536.     ,   544.     ,   552.     ,   560.     ,   568.     ,   
                          576.     ,   584.     ,   592.     ,   600.     ,   608.     ,   616.     ,   624.     ,   632.     ,   
                          640.     ,   648.     ,   656.     ,   664.     ,   672.     ,   680.     ,   688.     ,   696.     ,   
                          704.     ,   712.     ,   720.     ,   728.     ,   736.     ,   744.     ,   752.     ,   760.     ,   
                          768.     ,   776.     ,   784.     ,   792.     ,   800.     ,   808.     ,   816.     ,   824.     ,   
                          832.     ,   840.     ,   848.     ,   856.     ,   864.     ,   872.     ,   880.     ,   888.     ,   
                          896.     ,   904.     ,   912.     ,   920.     ,   928.     ,   936.     ,   944.     ,   952.     ,   
                          960.     ,   968.     ,   976.     ,   984.     ,   992.     ,  1000.     ,  1008.     ,  1016.     ,  
                          1024.     ,  1040.     ,  1056.     ,  1072.     ,  1088.     ,  1104.     ,  1120.     ,  1136.     , 
                          1152.     ,  1168.     ,  1184.     ,  1200.     ,  1216.     ,  1232.     ,  1248.     ,  1264.     ,  
                          1280.     ,  1296.     ,  1312.     ,  1328.     ,  1344.     ,  1360.     ,  1376.     ,  1392.     ,  
                          1408.     ,  1424.     ,  1440.     ,  1456.     ,  1472.     ,  1488.     ,  1504.     ,  1520.     ,  
                          1536.     ,  1552.     ,  1568.     ,  1584.     ,  1600.     ,  1616.     ,  1632.     ,  1648.     ,  
                          1664.     ,  1680.     ,  1696.     ,  1712.     ,  1728.     ,  1744.     ,  1760.     ,  1776.     ,  
                          1792.     ,  1808.     ,  1824.     ,  1840.     ,  1856.     ,  1872.     ,  1888.     ,  1904.     ,  
                          1920.     ,  1936.     ,  1952.     ,  1968.     ,  1984.     ,  2000.     ,  2016.     ,  2032.     ,  
                          2048.     ,  2080.     ,  2112.     ,  2144.     ,  2176.     ,  2208.     ,  2240.     ,  2272.     ,  
                          2304.     ,  2336.     ,  2368.     ,  2400.     ,  2432.     ,  2464.     ,  2496.     ,  2528.     ,  
                          2560.     ,  2592.     ,  2624.     ,  2656.     ,  2688.     ,  2720.     ,  2752.     ,  2784.     ,  
                          2816.     ,  2848.     ,  2880.     ,  2912.     ,  2944.     ,  2976.     ,  3008.     ,  3040.     ,  
                          3072.     ,  3104.     ,  3136.     ,  3168.     ,  3200.     ,  3232.     ,  3264.     ,  3296.     ,  
                          3328.     ,  3360.     ,  3392.     ,  3424.     ,  3456.     ,  3488.     ,  3520.     ,  3552.     ,  
                          3584.     ,  3616.     ,  3648.     ,  3680.     ,  3712.     ,  3744.     ,  3776.     ,  3808.     ,  
                          3840.     ,  3872.     ,  3904.     ,  3936.     ,  3968.     ,  4000.     ,  4032.     ,  4064.     ,  
                          4096.     ,  4160.     ,  4224.     ,  4288.     ,  4352.     ,  4416.     ,  4480.     ,  4544.     ,  
                          4608.     ,  4672.     ,  4736.     ,  4800.     ,  4864.     ,  4928.     ,  4992.     ,  5056.     ,  
                          5120.     ,  5184.     ,  5248.     ,  5312.     ,  5376.     ,  5440.     ,  5504.     ,  5568.     ,  
                          5632.     ,  5696.     ,  5760.     ,  5824.     ,  5888.     ,  5952.     ,  6016.     ,  6080.     ,  
                          6144.     ,  6208.     ,  6272.     ,  6336.     ,  6400.     ,  6464.     ,  6528.     ,  6592.     ,  
                          6656.     ,  6720.     ,  6784.     ,  6848.     ,  6912.     ,  6976.     ,  7040.     ,  7104.     ,  
                          7168.     ,  7232.     ,  7296.     ,  7360.     ,  7424.     ,  7488.     ,  7552.     ,  7616.     ,  
                          7680.     ,  7744.     ,  7808.     ,  7872.     ,  7936.     ,  8000.     ,  8064.     ,  8128.     ,  
                          8192.     ,  8320.     ,  8448.     ,  8576.     ,  8704.     ,  8832.     ,  8960.     ,  9088.     ,  
                          9216.     ,  9344.     ,  9472.     ,  9600.     ,  9728.     ,  9856.     ,  9984.     , 10112.     , 
                          10240.     , 10368.     , 10496.     , 10624.     , 10752.     , 10880.     , 11008.     , 11136.     , 
                          11264.     , 11392.     , 11520.     , 11648.     , 11776.     , 11904.     , 12032.     , 12160.     , 
                          12288.     , 12416.     , 12544.     , 12672.     , 12800.     , 12928.     , 13056.     , 13184.     , 
                          13312.     , 13440.     , 13568.     , 13696.     , 13824.     , 13952.     , 14080.     , 14208.     , 
                          14336.     , 14464.     , 14592.     , 14720.     , 14848.     , 14976.     , 15104.     , 15232.     , 
                          15360.     , 15488.     , 15616.     , 15744.     , 15872.     , 16000.     , 16128.     , 16256.     , 
                          16384.     , 16640.     , 16896.     , 17152.     , 17408.     , 17664.     , 17920.     , 18176.     , 
                          18432.     , 18688.     , 18944.     , 19200.     , 19456.     , 19712.     , 19968.     , 20224.     , 
                          20480.     , 20736.     , 20992.     , 21248.     , 21504.     , 21760.     , 22016.     , 22272.     , 
                          22528.     , 22784.     , 23040.     , 23296.     , 23552.     , 23808.     , 24064.     , 24320.     , 
                          24576.     , 24832.     , 25088.     , 25344.     , 25600.     , 25856.     , 26112.     , 26368.     , 
                          26624.     , 26880.     , 27136.     , 27392.     , 27648.     , 27904.     , 28160.     , 28416.     , 
                          28672.     , 28928.     , 29184.     , 29440.     , 29696.     , 29952.     , 30208.     , 30464.     , 
                          30720.     , 30976.     , 31232.     , 31488.     , 31744.     , 32000.     , 32256.     , 32512.     , 
                          32768.     , 33280.     , 33792.     , 34304.     , 34816.     , 35328.     , 35840.     , 36352.     , 
                          36864.     , 37376.     , 37888.     , 38400.     , 38912.     , 39424.     , 39936.     , 40448.     , 
                          40960.     , 41472.     , 41984.     , 42496.     , 43008.     , 43520.     , 44032.     , 44544.     , 
                          45056.     , 45568.     , 46080.     , 46592.     , 47104.     , 47616.     , 48128.     , 48640.     , 
                          49152.     , 49664.     , 50176.     , 50688.     , 51200.     , 51712.     , 52224.     , 52736.     , 
                          53248.     , 53760.     , 54272.     , 54784.     , 55296.     , 55808.     , 56320.     , 56832.     , 
                          57344.     , 57856.     , 58368.     , 58880.     , 59392.     , 59904.     , 60416.     , 60928.     , 
                          61440.     , 61952.     , 62464.     , 62976.     , 63488.     , 64000.     , 64512.     , 65024.     ])
    
    before_value_array = np.atleast_1d(before_value)
    sign_array = np.sign(before_value_array)
    abs_before_value = np.abs(before_value_array)
    abs_diff = np.abs(abs_before_value[:, None] - reference)
    abs_diff[abs_before_value[:, None] < reference] = np.inf
    indices = np.argmin(abs_diff, axis=1)
    
    after_value = reference[indices]
    result = sign_array * after_value
    
    return result if isinstance(before_value, np.ndarray) else result[0]


neuron_param = {}
neuron_param['tau'] = checkAccurateTimeConst(parameters['neuron_tau'], parameters['refractory'], 0.5, 5)[0] * b2.ms
neuron_param['refractory'] = checkAccurateTimeConst(parameters['neuron_tau'], parameters['refractory'], 0.5, 5)[1] * b2.ms
neuron_param['reset'] = 'v = 0'
neuron_param['threshold'] = 'v>'+str(parameters['threshold'])
neuron_model = '''
dv/dt = -v / tau : 1 (unless refractory)
tau : second
'''

synapse_param = {}
synapse_param['taupre'] = checkAccurateTimeConst(parameters['synapse_tau'], 0, 0.5, 5)[0] #parameters['synapse_tau'] #checkAccurateTimeConst(parameters['synapse_tau'], 0, 0.5, 5)[0]
synapse_param['taupost'] = checkAccurateTimeConst(parameters['synapse_tau'], 0, 0.5, 5)[0] #parameters['synapse_tau'] #checkAccurateTimeConst(parameters['synapse_tau'], 0, 0.5, 5)[0]
synapse_param['wmax'] = parameters['wmax']
synapse_param['winit'] = parameters['winit']
synapse_param['apre'] = parameters['apre']
if parameters['gamma'] < 0:
    synapse_param['apost'] = get_nearest_value34(synapse_param['apre']*(1/np.abs(parameters['gamma'])))
else:
    synapse_param['apost'] = get_nearest_value34(synapse_param['apre']*(np.abs(parameters['gamma'])))

synapse_model = '''
w : 1
pre : 1
post : 1
lpre : 1
is_onpre : 1
is_onpost : 1
'''

synapse_onpre = '''
is_onpre = 1
is_onpost = 0
'''

synapse_onpost = '''
is_onpre = 0
is_onpost = 1
'''

snn_obj = {}
snn_obj['input'] = b2.SpikeGeneratorGroup(N=2, indices=input_spike_idx, times=input_spike_time*b2.second)

snn_obj['neuron'] = b2.NeuronGroup(N = 2, 
                                   model = neuron_model, 
                                   threshold = neuron_param['threshold'], 
                                   reset=neuron_param['reset'], 
                                   refractory = neuron_param['refractory'], 
                                   method = 'exact')
snn_obj['neuron'].tau = neuron_param['tau']

snn_obj['input_synapse'] = b2.Synapses(source = snn_obj['input'], 
                                       target = snn_obj['neuron'], 
                                       model = 'w : 1', 
                                       on_pre = 'v_post += w', 
                                       method='exact')
snn_obj['input_synapse'].connect(condition='i==j')
snn_obj['input_synapse'].w = synapse_param['wmax']

snn_obj['synapse'] = b2.Synapses(source = snn_obj['neuron'], 
                                 target = snn_obj['neuron'], 
                                 model = synapse_model, 
                                 on_pre = synapse_onpre, 
                                 on_post = synapse_onpost, 
                                 namespace = synapse_param, 
                                 method='exact')
snn_obj['synapse'].connect(i=0, j=1)
snn_obj['synapse'].w = synapse_param['winit']
snn_obj['synapse'].pre = 0
snn_obj['synapse'].post = 0
snn_obj['synapse'].lpre = 0
snn_obj['synapse'].is_onpre = 0
snn_obj['synapse'].is_onpost = 0

snn_obj['synapse_spikemonitor'] = b2.SpikeMonitor(source=snn_obj['neuron'], record=True)
snn_obj['synapse_statemonitor'] = b2.StateMonitor(source=snn_obj['synapse'], variables = ['w', 'pre', 'post', 'lpre', 'is_onpre', 'is_onpost'], record=True)
snn_obj['sample'] = b2.StateMonitor(source=snn_obj['synapse'], variables = ['post'], record=True)

def network_operation_FP34():
    snn_obj['synapse'].pre *= np.exp(-(0.5)/synapse_param['taupre'])
    snn_obj['synapse'].post *= np.exp(-(0.5)/synapse_param['taupost'])
    snn_obj['synapse'].pre = get_nearest_value64(snn_obj['synapse'].pre)
    snn_obj['synapse'].post = get_nearest_value64(snn_obj['synapse'].post)
    if snn_obj['synapse'].is_onpre == 1:
        snn_obj['synapse'].pre = get_nearest_value64(snn_obj['synapse'].pre + synapse_param['apre'])
        # snn_obj['synapse'].pre += synapse_param['apre']   
        # snn_obj['synapse'].w = get_nearest_value34(snn_obj['synapse'].w + snn_obj['synapse'].lpre)
        # snn_obj['synapse'].w = get_nearest_value34(snn_obj['synapse'].w - snn_obj['synapse'].post)
        # snn_obj['synapse'].w = np.clip(snn_obj['synapse'].w, 0, synapse_param['wmax'])
        print(f"LTP: {get_nearest_value34(snn_obj['synapse'].lpre)}")
        print(f"LTD: {get_nearest_value34(snn_obj['synapse'].post)}")
        snn_obj['synapse'].w = np.clip(get_nearest_value34(get_nearest_value34(snn_obj['synapse'].w + snn_obj['synapse'].lpre) - snn_obj['synapse'].post), 0, synapse_param['wmax'])
        snn_obj['synapse'].lpre = 0
        snn_obj['synapse'].is_onpre = 0
        
    elif snn_obj['synapse'].is_onpost == 1:
        snn_obj['synapse'].post = get_nearest_value64(snn_obj['synapse'].post + synapse_param['apost'])
        # snn_obj['synapse'].post += synapse_param['apost']
        snn_obj['synapse'].lpre = snn_obj['synapse'].pre
        snn_obj['synapse'].is_onpost = 0
        

    
network = b2.Network()
network_operation = b2.NetworkOperation(network_operation_FP34, dt=0.5*b2.ms)
for key in snn_obj.keys():
    network.add(snn_obj[key])
network.add(network_operation)

network.run((np.max(input_spike_time)+0.01)*b2.second, report='stdout')

pre_spike_time = input_spike_time[np.where(input_spike_idx==0)[0]]*1000
post_spike_time = input_spike_time[np.where(input_spike_idx==1)[0]]*1000

brian2_spike_idx = snn_obj['synapse_spikemonitor'].i[:]
brian2_spike_time = snn_obj['synapse_spikemonitor'].t[:]/b2.second
brian2_statemonitor_time = snn_obj['synapse_statemonitor'].t[:]/b2.ms
brian2_final_weight = snn_obj['synapse'].w[:]

brian2_LTD = np.zeros(len(pre_spike_time))
brian2_LTP = np.zeros(len(post_spike_time))
pre_trace = snn_obj['synapse_statemonitor'].pre[:][0]
post_trace = snn_obj['synapse_statemonitor'].post[:][0]
for i in range(len(post_spike_time)):
    print(np.where(brian2_statemonitor_time == post_spike_time[i])[0])
    brian2_LTP[i] = pre_trace[np.where(brian2_statemonitor_time == post_spike_time[i]+0.5)[0].item()]
for i in range(len(pre_spike_time)):
    brian2_LTD[i] = post_trace[np.where(brian2_statemonitor_time == pre_spike_time[i]+0.5)[0].item()]

print('='*40)
print('Input spike pattern')
print('-'*40)
print(f'spike index : {input_spike_idx}')
print(f'spike time  : {input_spike_time} \n')
print('Output spike pattern')
print('-'*40)
print('Neu+')
print(f'spike index : {output_spike_idx}')
print(f'spike time  : {output_spike_time}')
print('Brian2')
print(f'spike index : {brian2_spike_idx}')
print(f'spike time  : {brian2_spike_time} \n')
print('Final synaptic weight & update amount')
print('-'*40)
print(f'Neu+ : {synDecompiledList[2][:].item()}')
print(f'Brian2 : {brian2_final_weight}')
print(f'LTP (pre-post pair) : {brian2_LTP}')
print(f'LTD (post-pre pair) : {brian2_LTD} \n')
print('Parameters')
print('-'*40)
print(f"apre : {synapse_param['apre']}")
print(f"apost : {synapse_param['apost']}")
print(f"gamma : {parameters['gamma']}")
print(f"winit : {synapse_param['winit']}")
print(f"wmax : {synapse_param['wmax']}")
print(f"synapse time constant : {synapse_param['taupre']}")
print(f"neuron time constant : {neuron_param['tau']}")
print(f"neuron threshold : {parameters['threshold']}")
print(f"neuron refractory : {parameters['refractory']}")


